{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your data in the supported format, and a spaCy model with vectors you can \n",
    "use the spacy_ann CLI to compute the nearest neighbors index for your Aliases and tran an \n",
    "Encoder for disambiguating entity spans to their canonical Id\n",
    " \n",
    "Usage:\n",
    "```console\n",
    "spacy_ann create_index en_core_web_md examples/tutorial/data examples/tutorial/models\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_ann import AnnLinker\n",
    "\n",
    "# Load the spaCy model from the output_dir you used from the create_index command\n",
    "model_dir = \"models/ann_linker/\"\n",
    "nlp = spacy.load(model_dir)\n",
    "\n",
    "# The NER component of the en_core_web_md model doesn't actually recognize the aliases as entities\n",
    "# so we'll add a spaCy EntityRuler component for now to extract them.\n",
    "# ruler = nlp.create_pipe('entity_ruler')\n",
    "# patterns = [{\"label\": \"SKILL\", \"pattern\": alias} for alias in nlp.get_pipe('ann_linker').kb.get_alias_strings()]\n",
    "# ruler.add_patterns(patterns)\n",
    "# nlp.add_pipe(ruler, before=\"ann_linker\")\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before=\"ann_linker\")\n",
    "patterns = [{\"label\": \"SKILL\", \"pattern\": alias} for alias in nlp.get_pipe('ann_linker').kb.get_alias_strings()]\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NLP', 'ORG', 'a3'), ('Machine', 'ORG', '')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"NLP is a highly researched subset of Machine learning.\")\n",
    "[(e.text, e.label_, e.kb_id_) for e in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.171593248390084"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "import numpy as np\n",
    "entities = list(srsly.read_jsonl('data/entities.jsonl'))\n",
    "natl_doc = nlp.make_doc(entities[2]['description'])\n",
    "neur_doc = nlp.make_doc(entities[3]['description']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.2457936, 2.6232092], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_encodings = np.asarray([natl_doc.vector, neur_doc.vector])\n",
    "entity_norm = np.linalg.norm(entity_encodings, axis=1)\n",
    "entity_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = np.dot(entity_encodings, doc.vector.T) / (doc.vector_norm * entity_norm)\n",
    "sims.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {\"label\": \"SKILL\", \"pattern\": alias}\n",
    "    for alias in nlp.get_pipe('ann_linker').kb.get_alias_strings()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NLP', 'ORG', 'a3', [AliasCandidate(alias='NLP', similarity=1.0)]), ('Machine', 'ORG', '', [])]\n"
     ]
    }
   ],
   "source": [
    "print([(e.text, e.label_, e.kb_id_, e._.alias_candidates) for e in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "More text about nlpe"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"More text about nlpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = list(doc.ents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NLP, Machine)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural language processing', 'SKILL', 'a3'), ('NLP', 'ORG', 'a3')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "[(e.text, e.label_, e.kb_id_) for e in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
